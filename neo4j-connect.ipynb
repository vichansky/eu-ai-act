{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2c9c7b-4de1-427a-b685-1b73a995c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "# import dotenv\n",
    "# import os\n",
    "\n",
    "# # Use verify_connectivity() method to ensure that a working connection can be established with a 'Driver' instance\n",
    "# load_status = dotenv.load_dotenv(\"Neo4j-e68dbc41-Created-2025-01-27.txt\")\n",
    "# if load_status is False:\n",
    "#     raise RuntimeError('Environment variables not loaded.')\n",
    "\n",
    "# URI = os.getenv(\"NEO4J_URI\")\n",
    "# AUTH = (os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    "\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from utils.config import OPENAI_API_KEY, AURA_URI, AURA_USERNAME, AURA_PASSWORD\n",
    "\n",
    "URI = AURA_URI\n",
    "AUTH = (AURA_USERNAME, AURA_PASSWORD)\n",
    "\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Connection established.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c47683-9d7b-4e8a-a07b-45e620b9e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab3dfa7-529d-476a-b4b1-2572cb165ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe EU AI Act, officially known as the Artificial Intelligence Act, is a proposed legislation by the European Commission aimed at regulating the development and use of artificial intelligence (AI) in the European Union. It was introduced in April 2021 and is currently under review by the European Parliament and the Council of the EU.\\n\\nSome key points about the EU AI Act include:\\n\\n1. Scope and definitions: The act defines AI systems as software that is designed to interact with the environment and take decisions or actions without human intervention. It covers AI systems that are developed, sold, or used in the EU, regardless of where they were created.\\n\\n2. Risk-based approach: The act introduces a risk-based approach, where AI systems are categorized into four levels of risk - unacceptable, high, limited, and minimal. The higher the risk, the stricter the requirements for their development and use.\\n\\n3. Bans and restrictions: The act proposes a ban on certain AI practices that are considered unacceptable risks, such as AI systems that manipulate human behavior or use subliminal techniques. It also restricts the use of AI in areas such as social scoring and biometric categorization.\\n\\n4. Transparency and accountability: The act requires AI systems to be transparent, meaning that users should be informed that they are'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What do you know about the EU AI Act?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8d9c3-81d6-4673-94b0-ed268e1f90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "1. High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which they are in use.\n",
    "\n",
    "2. Human oversight shall aim to prevent or minimise the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, in particular where such risks persist despite the application of other requirements set out in this\n",
    "Section.\n",
    "\n",
    "3. The oversight measures shall be commensurate with the risks, level of autonomy and context of use of the high-risk AI system, and shall be ensured through either one or both of the following types of measures:\n",
    "\n",
    "(a) measures identified and built, when technically feasible, into the high-risk AI system by the provider before it is placed on the market or put into service;\n",
    "\n",
    "(b) measures identified by the provider before placing the high-risk AI system on the market or putting it into service and that are appropriate to be implemented by the deployer.\n",
    "\n",
    "4. For the purpose of implementing paragraphs 1, 2 and 3, the high-risk AI system shall be provided to the deployer in such a way that natural persons to whom human oversight is assigned are enabled, as appropriate and proportionate:\n",
    "\n",
    "(a) to properly understand the relevant capacities and limitations of the high-risk AI system and be able to duly monitor its operation, including in view of detecting and addressing anomalies, dysfunctions and unexpected performance;\n",
    "\n",
    "(b) to remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (automation bias), in particular for high-risk AI systems used to provide information or recommendations for decisions to be taken by natural persons;\n",
    "\n",
    "(c) to correctly interpret the high-risk AI system’s output, taking into account, for example, the interpretation tools and methods available;\n",
    "\n",
    "(d) to decide, in any particular situation, not to use the high-risk AI system or to otherwise disregard, override or reverse the output of the high-risk AI system;\n",
    "\n",
    "(e) to intervene in the operation of the high-risk AI system or interrupt the system through a ‘stop’ button or a similar procedure that allows the system to come to a halt in a safe state.\n",
    "\n",
    "5. For high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 of this Article shall be such as to ensure that, in addition, no action or decision is taken by the deployer on the basis of the identification resulting from the system unless that identification has been separately verified and confirmed by at least two natural persons with the necessary competence, training and authority. The requirement for a separate verification by at least two natural persons shall not apply to high-risk AI systems used for the purposes of law enforcement, migration, border control or asylum, where Union or national law considers the application of this requirement to be disproportionate.\n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45089b7f-261b-4e67-92ff-48c8bbfe9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ai_dataframe = pd.read_csv(\"data/processed_and_formatted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e5e902f1-9229-4159-8bbc-0d11f1422711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs.neo4j_graph import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_experimental.graph_transformers.llm import LLMGraphTransformer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from uuid import uuid4\n",
    "\n",
    "# Step 1: Set up Neo4jGraph\n",
    "graph = Neo4jGraph(\n",
    "    url=AURA_URI,\n",
    "    username=AURA_USERNAME,\n",
    "    password=AURA_PASSWORD\n",
    ")\n",
    "\n",
    "# Ensure the schema avoids duplicate nodes\n",
    "with graph._driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (n:Entity) REQUIRE n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (r:Relation) REQUIRE r.id IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f8480788-fe7b-457c-ad25-96cbd13cd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text column into LangChain Document objects\n",
    "documents = [Document(page_content=text, metadata={\"id\": str(uuid4())}) for text in ai_dataframe['Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4366f84f-0f20-4296-a3b4-3239921f11cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define the LLM and PromptTemplate\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "template = \"Extract entities and relationships from the following text: {text}\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fec8e201-6d3c-4a99-a9cd-dfaf8ef01f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of Runnables, use the pipe operator to chain the prompt and the LLM\n",
    "llm_pipeline = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5acaff2d-b450-4993-b2e3-955df64c661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks based on a token limit\n",
    "def split_text_into_chunks(text, max_tokens=4000):\n",
    "    \"\"\"Splits the text into smaller chunks based on token count.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "    token_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        # Estimate tokens as words (this is an approximation; for more precision, use a tokenizer like tiktoken)\n",
    "        token_count += len(word.split())\n",
    "        if token_count > max_tokens:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = [word]\n",
    "            token_count = len(word.split())\n",
    "        else:\n",
    "            chunk.append(word)\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ad30f8f2-5317-4b40-a74f-968a43a1c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split large documents into smaller chunks if necessary\n",
    "max_tokens = 4000  # Adjust this based on the model's context window\n",
    "chunked_documents = []\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = split_text_into_chunks(doc.page_content, max_tokens)\n",
    "    chunked_documents.extend([Document(page_content=chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b1a15d57-aa7b-4636-950d-e51d0fb581a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the documents using the LLM pipeline\n",
    "graph_documents = llm_pipeline.invoke(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8fbe3197-7afe-4c0a-a0c6-05f4d2dfa1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, graph_doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graph_documents):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_doc\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelationships: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_doc\u001b[38;5;241m.\u001b[39mrelationships\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "# Iterate over the graph documents and print nodes and relationships for each document\n",
    "for i, graph_doc in enumerate(graph_documents):\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    print(f\"Nodes: {graph_doc.nodes}\")\n",
    "    print(f\"Relationships: {graph_doc.relationships}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2ab74b78-2aff-4329-8bf8-e2138262dc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the provided text, here are the extracted entities and relationships:\\n\\n### Entities:\\n1. **European Union (EU)**\\n2. **European Commission**\\n3. **AI Office**\\n4. **Member States**\\n5. **Market Surveillance Authorities**\\n6. **Providers of AI Systems**\\n7. **Deployers of AI Systems**\\n8. **Notified Bodies**\\n9. **General-Purpose AI Models**\\n10. **High-Risk AI Systems**\\n11. **Vulnerable Groups**\\n12. **Scientific Panel of Independent Experts**\\n13. **Advisory Forum**\\n14. **Conformity Assessment Bodies**\\n15. **Data Protection Authorities**\\n16. **Civil Society Organizations**\\n17. **Small and Medium-sized Enterprises (SMEs)**\\n18. **Public Authorities**\\n19. **Law Enforcement Authorities**\\n20. **Consumers**\\n21. **Affected Persons**\\n22. **Technical Documentation**\\n23. **Risk Management System**\\n24. **Biometric Data**\\n25. **Deepfake Technology**\\n26. **AI Regulatory Sandboxes**\\n27. **Harmonised Standards**\\n28. **Codes of Conduct**\\n29. **Transparency Obligations**\\n30. **Cybersecurity Requirements**\\n\\n### Relationships:\\n1. **EU Commission** oversees the implementation of AI regulations and establishes the **AI Office**.\\n2. **Member States** are required to designate **Market Surveillance Authorities** to enforce AI regulations.\\n3. **Providers of AI Systems** must ensure compliance with regulations and maintain **Technical Documentation**.\\n4. **Deployers of AI Systems** are responsible for using AI systems according to the provided instructions and ensuring human oversight.\\n5. **Notified Bodies** assess the conformity of **High-Risk AI Systems** and provide certifications.\\n6. **General-Purpose AI Models** can be classified as **High-Risk AI Systems** based on their capabilities and intended use.\\n7. **Vulnerable Groups** are specifically protected under the regulations to prevent discrimination and ensure their rights.\\n8. The **Scientific Panel of Independent Experts** provides advice and alerts the **AI Office** about potential risks associated with AI models.\\n9. The **Advisory Forum** includes stakeholders from various sectors to contribute to the development of AI regulations.\\n10. **Conformity Assessment Bodies** must comply with the requirements set by the **EU Commission** and are responsible for evaluating AI systems.\\n11. **Data Protection Authorities** ensure compliance with data protection laws in relation to AI systems.\\n12. **Small and Medium-sized Enterprises (SMEs)** receive support and guidance to comply with AI regulations.\\n13. **AI Regulatory Sandboxes** provide a controlled environment for testing AI systems before they are placed on the market.\\n14. **Harmonised Standards** are established to ensure compliance and facilitate the free movement of AI systems within the EU.\\n15. **Codes of Conduct** are developed to promote voluntary adherence to AI regulations and best practices.\\n16. **Transparency Obligations** require providers to disclose information about AI systems and their outputs, especially in cases of biometric data processing.\\n17. **Cybersecurity Requirements** are imposed on providers to protect AI systems from vulnerabilities and attacks.\\n\\n### Summary of Relationships:\\n- The **EU Commission** and **Member States** work together to establish a regulatory framework for AI systems.\\n- **Providers** and **Deployers** of AI systems have specific obligations to ensure compliance with regulations, including maintaining documentation and ensuring human oversight.\\n- **Market Surveillance Authorities** monitor compliance and can take action against non-compliant systems.\\n- **Notified Bodies** play a crucial role in assessing and certifying high-risk AI systems.\\n- The **AI Office** and **Scientific Panel** provide oversight and expert advice to ensure the effective implementation of AI regulations.\\n- **Vulnerable Groups** are protected under the regulations to prevent discrimination and ensure their rights are upheld.\\n\\nThis structured overview captures the key entities and their interrelationships as described in the provided text.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 798, 'prompt_tokens': 118894, 'total_tokens': 119692, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-48b7dc79-4d58-4a16-bff0-f01ef78abb52-0')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "70c158b1-eb04-475b-a245-aa5cf203507e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transform documents into a graph\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[0;32m----> 3\u001b[0m     graph_transformer\u001b[38;5;241m.\u001b[39mconvert_to_graph_documents(documents\u001b[38;5;241m=\u001b[39m[doc])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Validate the graph creation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39m_driver\u001b[38;5;241m.\u001b[39msession() \u001b[38;5;28;01mas\u001b[39;00m session:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "# Transform documents into a graph\n",
    "for doc in documents:\n",
    "    graph_transformer.convert_to_graph_documents(documents=[doc])\n",
    "\n",
    "# Validate the graph creation\n",
    "with graph._driver.session() as session:\n",
    "    results = session.run(\"MATCH (n) RETURN n LIMIT 10\")\n",
    "    for record in results:\n",
    "        print(record)\n",
    "\n",
    "print(\"Graph creation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cca082a2-7326-4df1-ae6f-0cd76c9769c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LLMGraphTransformer.__init__() got an unexpected keyword argument 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m graph_documents \u001b[38;5;241m=\u001b[39m llm_pipeline\u001b[38;5;241m.\u001b[39minvoke(chunked_documents)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Ensure LLMGraphTransformer is applied for knowledge graph transformation\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m graph_transformer \u001b[38;5;241m=\u001b[39m LLMGraphTransformer(graph\u001b[38;5;241m=\u001b[39mgraph, documents\u001b[38;5;241m=\u001b[39mgraph_documents)\n",
      "\u001b[0;31mTypeError\u001b[0m: LLMGraphTransformer.__init__() got an unexpected keyword argument 'graph'"
     ]
    }
   ],
   "source": [
    "from langchain.graphs.neo4j_graph import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from uuid import uuid4\n",
    "import re\n",
    "\n",
    "# Step 1: Set up Neo4jGraph\n",
    "graph = Neo4jGraph(\n",
    "    url=AURA_URI,\n",
    "    username=AURA_USERNAME,\n",
    "    password=AURA_PASSWORD\n",
    ")\n",
    "\n",
    "# Ensure the schema avoids duplicate nodes\n",
    "with graph._driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (n:Entity) REQUIRE n.id IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (r:Relation) REQUIRE r.id IS UNIQUE\")\n",
    "\n",
    "# Convert text column into LangChain Document objects\n",
    "documents = [Document(page_content=text, metadata={\"id\": str(uuid4())}) for text in ai_dataframe['Content']]\n",
    "\n",
    "# Define the LLM and PromptTemplate\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "template = \"Extract entities and relationships from the following text: {text}\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Instead of Runnables, use the pipe operator to chain the prompt and the LLM\n",
    "llm_pipeline = prompt | llm\n",
    "\n",
    "# Function to split text into chunks based on token limit while preserving context\n",
    "def split_text_into_chunks(text, max_tokens=4000):\n",
    "    \"\"\"Splits the text into smaller chunks while preserving sentences and relationships.\"\"\"\n",
    "    \n",
    "    # Split text into sentences for better chunking\n",
    "    sentences = re.split(r'(?<=\\.|\\?)\\s', text)  # This will split the text by sentences (e.g., ending with period or question mark)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_token_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Estimate token count based on word count\n",
    "        tokens_in_sentence = len(sentence.split())\n",
    "        \n",
    "        # If adding this sentence exceeds the token limit, create a new chunk\n",
    "        if current_token_count + tokens_in_sentence > max_tokens:\n",
    "            if current_chunk:  # Avoid adding empty chunks\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_token_count = tokens_in_sentence\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_token_count += tokens_in_sentence\n",
    "\n",
    "    # Add any remaining chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Split large documents into smaller chunks if necessary\n",
    "max_tokens = 4000  # Adjust this based on the model's context window\n",
    "chunked_documents = []\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = split_text_into_chunks(doc.page_content, max_tokens)\n",
    "    chunked_documents.extend([Document(page_content=chunk) for chunk in chunks])\n",
    "\n",
    "# Process the documents using the LLM pipeline\n",
    "graph_documents = llm_pipeline.invoke(chunked_documents)\n",
    "\n",
    "# # Ensure LLMGraphTransformer is applied for knowledge graph transformation\n",
    "# graph_transformer = LLMGraphTransformer(graph=graph, documents=graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b5ed28ed-a7be-49b7-bf92-c055cfe3e4f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print out the nodes and relationships from graph_documents\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m graph_documents:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mmetadata:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "# Print out the nodes and relationships from graph_documents\n",
    "for doc in graph_documents:\n",
    "    print(f\"Document ID: {doc.metadata['id']}\")\n",
    "    if 'nodes' in doc.metadata:\n",
    "        print(f\"Nodes: {doc.metadata['nodes']}\")\n",
    "    if 'relationships' in doc.metadata:\n",
    "        print(f\"Relationships: {doc.metadata['relationships']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "86f49501-b71d-489b-9f05-c5b3804dcef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', 'Based on the provided text, here are the extracted entities and relationships:\\n\\n### Entities:\\n1. **AI Systems**: Refers to various artificial intelligence systems, including high-risk AI systems and general-purpose AI models.\\n2. **Providers**: Individuals or organizations that develop and place AI systems on the market.\\n3. **Deployers**: Individuals or organizations that use AI systems.\\n4. **Market Surveillance Authorities**: National authorities responsible for monitoring compliance with AI regulations.\\n5. **European Commission**: The executive branch of the European Union responsible for proposing legislation and implementing decisions.\\n6. **AI Office**: A body established to oversee the implementation of AI regulations and provide expertise.\\n7. **Notified Bodies**: Organizations designated to assess the conformity of AI systems with regulations.\\n8. **Affected Persons**: Individuals who are impacted by the use of AI systems.\\n9. **Vulnerable Groups**: Specific demographics that may be disproportionately affected by AI systems, such as children, the elderly, or disabled individuals.\\n10. **Scientific Panel**: A group of independent experts providing advice and support regarding AI regulations.\\n11. **Advisory Forum**: A group that provides technical expertise and advice to the Board and the Commission.\\n12. **Member States**: Countries that are part of the European Union.\\n13. **General-Purpose AI Models**: AI models that can perform a wide range of tasks and may be used in various applications.\\n\\n### Relationships:\\n1. **Providers and Deployers**: Providers create AI systems, while deployers use them. Both have specific obligations under the regulation.\\n2. **Market Surveillance Authorities and Providers**: Market surveillance authorities monitor and enforce compliance of providers with AI regulations.\\n3. **European Commission and AI Office**: The European Commission oversees the AI Office, which implements and enforces AI regulations.\\n4. **Notified Bodies and Providers**: Notified bodies assess the conformity of AI systems developed by providers.\\n5. **Scientific Panel and AI Office**: The scientific panel provides expertise and alerts the AI Office about potential risks associated with AI models.\\n6. **Advisory Forum and Board**: The advisory forum advises the Board and the Commission on AI regulations and practices.\\n7. **Member States and European Commission**: Member States must inform the European Commission about their national authorities and compliance measures.\\n8. **Affected Persons and Deployers**: Affected persons have rights regarding decisions made by deployers based on AI system outputs.\\n9. **Vulnerable Groups and AI Systems**: AI systems must consider the impact on vulnerable groups, ensuring their rights are protected.\\n10. **General-Purpose AI Models and High-Risk AI Systems**: General-purpose AI models can be classified as high-risk based on their capabilities and intended use.\\n\\n### Summary of Key Relationships:\\n- **Compliance and Monitoring**: Providers must ensure their AI systems comply with regulations, and market surveillance authorities are responsible for monitoring this compliance.\\n- **Risk Management**: Providers of high-risk AI systems must implement risk management systems to identify and mitigate risks associated with their use.\\n- **Transparency and Accountability**: Deployers must inform affected persons about the use of AI systems and provide clear explanations for decisions made based on AI outputs.\\n- **Collaboration**: The AI Office, scientific panel, and advisory forum work together to ensure effective implementation and compliance with AI regulations across the EU.\\n\\nThis structured overview captures the essential entities and their interrelationships as described in the provided text.')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m doc \u001b[38;5;241m=\u001b[39m doc_tuple[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Access the first element (the actual Document object)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Now we can access metadata\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m nodes \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m      8\u001b[0m relationships \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelationships\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "# Assuming each item in graph_documents is a tuple, where the first element is the Document\n",
    "for doc_tuple in graph_documents:\n",
    "    print(doc_tuple)\n",
    "    doc = doc_tuple[0]  # Access the first element (the actual Document object)\n",
    "    \n",
    "    # Now we can access metadata\n",
    "    nodes = doc.metadata.get('nodes', [])\n",
    "    relationships = doc.metadata.get('relationships', [])\n",
    "    \n",
    "    print(f\"Document ID: {doc.metadata['id']}\")\n",
    "    \n",
    "    print(\"Nodes:\")\n",
    "    for node in nodes:\n",
    "        print(f\"  Node ID: {node['id']}, Name: {node.get('name', 'N/A')}\")\n",
    "    \n",
    "    print(\"Relationships:\")\n",
    "    for relationship in relationships:\n",
    "        print(f\"  Relationship Type: {relationship['type']}, From: {relationship['from']}, To: {relationship['to']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3feb5cb0-3632-4356-b16b-a34c7f9bd8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, graph_doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graph_documents):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_doc\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelationships: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_doc\u001b[38;5;241m.\u001b[39mrelationships\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "# Iterate over the graph documents and print nodes and relationships for each document\n",
    "for i, graph_doc in enumerate(graph_documents):\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    print(f\"Nodes: {graph_doc.nodes}\")\n",
    "    print(f\"Relationships: {graph_doc.relationships}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3414d5b-0f42-453e-8f27-df8a24edd749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
